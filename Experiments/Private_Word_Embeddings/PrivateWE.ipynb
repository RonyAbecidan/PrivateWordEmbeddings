{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  **Illustrative notebook** : Differentially Private Neural Representation\n",
    "\n",
    "*The code of this notebook for making the classifier is inspired by https://pytorch.org/tutorials/beginner/text_sentiment_ngrams_tutorial.html*\n",
    "\n",
    "We have adapted this code so that we can apply the strategy proposed by the authors which consists in making a robust DP-Private NLP classifier.\n",
    "\n",
    "**Remark : To make computations faster you could use Google Colab' GPU**\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/RonyAbecidan/PrivateWordEmbeddings/blob/main/Experiments/Private_Word_Embeddings/PrivateWE.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torchtext=='0.4'--quiet\n",
    "print('PLEASE RESTART RUNTIME AFTER INSTALLING THIS PACKAGE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "import torchtext\n",
    "import pickle\n",
    "from torchtext.datasets import text_classification\n",
    "from torch.utils.data.dataset import random_split\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import warnings\n",
    "# from DPWE import *\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First, we can define some functions that will be useful for the implementation of the DP word embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_batch(batch):\n",
    "    '''\n",
    "    @batch : a batch of embeddings\n",
    "    this function returns a normalized version of the embeddings so that their coefficients belong to [0,1]\n",
    "    '''\n",
    "    batch_size,dim=batch.size()\n",
    "    return torch.mul(batch-torch.min(batch,axis=1)[0].view(batch_size,-1),(1/(torch.max(batch,axis=1)[0]-torch.min(batch,axis=1)[0])).view(batch_size,-1))\n",
    "    \n",
    "def Laplace_mechanism(tensor,eps,s=1,random_state=None):\n",
    "    '''\n",
    "    @tensor : an embedding or a batch of embedding that we want to make private\n",
    "    @s : l1-sensibility (equals to 1 if the normalized above is applied)\n",
    "    @eps : the level of noise. A lower epsilon means a higher noise\n",
    "    @random_state : the random seed\n",
    "    this functions return a private embedding based on the Laplace mechanism\n",
    "    '''\n",
    "    rng = np.random.RandomState(random_state)\n",
    "    return tensor + torch.tensor(rng.laplace(scale=s/eps,size=tensor.size())).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In order to test their algorithms, we have chosen 2 famous NLP datasets for classification tasks : The \"AG dataset\" made of news associated to 4 categories and, the \"Yelp Polarity Reviews\" made of reviews on which we can analyse 2 sentiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NGRAMS = 2\n",
    "import os\n",
    "if not os.path.isdir('./.data'):\n",
    "    os.mkdir('./.data')\n",
    "AG_data, AG_test = text_classification.DATASETS['AG_NEWS'](root='./.data', ngrams=NGRAMS, vocab=None)\n",
    "Yelp_data, Yelp_test = text_classification.DATASETS['YelpReviewPolarity'](root='./.data', ngrams=NGRAMS, vocab=None)\n",
    "\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We cut our data for the training phase into 95% train, 5% validation\n",
    "\n",
    "#### Since the training time is non negligible, we have considered only 30000 sentences for the train sets and the valid sets gathered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_valid_loss = float('inf')\n",
    "ag_train_size = int(0.95*30000)\n",
    "AG_train_set,AG_valid_set = random_split(AG_data[0:30000], [ag_train_size, 30000 - ag_train_size])\n",
    "\n",
    "yelp_train_size = int(0.95*30000)\n",
    "Yelp_train_set,Yelp_valid_set = random_split(Yelp_data[0:30000], [yelp_train_size, 30000 - yelp_train_size])\n",
    "\n",
    "Yelp_train_set[0][1][0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As we can observe, the sentences have been already tokenized, i.e. each word of the vocabulary is associated to a number identifying him. The module `nn.Embedding()` of pytorch can transform these integers into one-hot vectors and pass them to a simple linear layer.\n",
    "\n",
    "#### Now, let's make the classifier we will use. Concretely, we are going to make several experiments and hence, it would great to have a classifier that can be adapted with few modifications according to the cases.\n",
    "\n",
    "#### Thus, we propose to make **a swiss knife classifier** that will enable us to observe all the \"interesting cases\". Basically, we are seeking for :\n",
    "\n",
    "- The test accuracy with a non private embedding and a classic training in order to have an idea of how much we lose/gain in utility when we will add noises\n",
    "- The test accuracy with a private embedding with a classic training in order to have an idea of how much we lose/gain in utilility when we will add noise in the training phase\n",
    "- The test accuracy with a private embedding and a robust training phase in which we add the noise to the embedded sentences from the training set.\n",
    "- The test accuracy with the adaptative training strategy we have precised in our report to see if it was a good strategy or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    '''\n",
    "    Swiss knife classifier enabling to test all the listed cases \n",
    "    '''\n",
    "    def __init__(self, vocab_size, embed_dim, num_class,noise=False,dropout_rate=False,random_state=0):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.vocab_size=vocab_size\n",
    "        self.embed_dim=embed_dim\n",
    "        self.num_class=num_class\n",
    "        self.noise=noise\n",
    "        self.dropout_rate=dropout_rate\n",
    "        self.random_state=random_state\n",
    "        \n",
    "        #Embeddings of the words\n",
    "        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, sparse=True)\n",
    "        #Linear layer enabling to do the classification\n",
    "        self.fc = nn.Linear(embed_dim, num_class)\n",
    "\n",
    "    #random initialization of the weights\n",
    "    def init_weights(self):\n",
    "        initrange = 0.5\n",
    "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.bias.data.zero_()\n",
    "        \n",
    "    def forward(self, text, offsets):\n",
    "        \n",
    "        #If a dropout rate is provided\n",
    "        if self.dropout_rate:\n",
    "            #dropout rescales the output by 1/(1-p)\n",
    "            text=nn.Dropout(p=self.dropout_rate)(text.float())*(1-self.dropout_rate)\n",
    "            \n",
    "        #Embeddings\n",
    "        embedded = self.embedding(text.long(), offsets)\n",
    "        #Normalization of the embedding\n",
    "        embedded=normalize_batch(embedded)\n",
    "        \n",
    "        #If a noise is provided\n",
    "        if self.noise:\n",
    "            embedded=Laplace_mechanism(tensor=embedded,eps=self.noise,random_state=None).float()\n",
    "           \n",
    "        return self.fc(embedded)\n",
    "\n",
    "#Typical loss for classification task also used by the authors\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "def generate_batch(batch):\n",
    "    '''This function handles the case where batch of sentences have different sizes '''\n",
    "    #list containing the labels for each element of the batch\n",
    "    label = torch.tensor([entry[0] for entry in batch])\n",
    "    text = [entry[1] for entry in batch]\n",
    "    #list of the sizes of each sentence\n",
    "    offsets = [0] + [len(entry) for entry in text]\n",
    "    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
    "    #Concatenation of the sentences\n",
    "    text = torch.cat(text)\n",
    "    return text, offsets, label\n",
    "\n",
    "#train the model on one epoch and return the loss and accuracy for this epoch.\n",
    "def train_func(train_set,model,optimizer,scheduler):\n",
    "    '''This function handles the training phase of a neural network'''\n",
    "    model.train()\n",
    "    # Train the model\n",
    "    train_loss = 0\n",
    "    train_acc = 0\n",
    "    data = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True,\n",
    "                      collate_fn=generate_batch)\n",
    "    \n",
    "    for i, (text, offsets, cls) in tqdm(enumerate(data)):\n",
    "        \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        text, offsets, cls = text.to(device), offsets.to(device), cls.to(device)\n",
    "        output = model(text, offsets).to(device)\n",
    "        loss = criterion(output, cls)\n",
    "        train_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_acc += (output.argmax(1) == cls).sum().item()\n",
    "        \n",
    "    clear_output(wait=True)\n",
    "    # Adjust the learning rate\n",
    "    scheduler.step()\n",
    "\n",
    "    return train_loss / len(train_set), train_acc / len(train_set)\n",
    "\n",
    "#Compute the accuracy on the validation and test sets\n",
    "def test(test_set,model):\n",
    "    '''This function handles the computation of the test accuracy after the training is ended'''\n",
    "    model.eval()\n",
    "    loss = 0\n",
    "    acc = 0\n",
    "    data = DataLoader(test_set, batch_size=BATCH_SIZE, collate_fn=generate_batch)\n",
    "    for text, offsets, cls in tqdm(data):\n",
    "        text, offsets, cls = text.to(device), offsets.to(device), cls.to(device)\n",
    "        with torch.no_grad():\n",
    "            output = model(text, offsets).to(device)\n",
    "            loss = criterion(output, cls)\n",
    "            loss += loss.item()\n",
    "            acc += (output.argmax(1) == cls).sum().item()\n",
    "\n",
    "    return loss / len(test_set), acc / len(test_set)\n",
    "\n",
    "def train(model,train_set,valid_set,test_set,nb_epochs=1,dropout=False,noise=False,noise_during_training=False,display=False,increasing_noise=False):\n",
    "    '''This function can simulate the different situations we have considered above and will enable\n",
    "    us to obtain the results wanted '''\n",
    "    model.to(device)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=2)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1, gamma=0.9)\n",
    "    model.init_weights()\n",
    "    #enables to active the \"robust strategy\"\n",
    "    model.noise = 0 if not(noise_during_training) else noise\n",
    "    #In all the cases, the dropout rate should be equal to 0 during the training phase\n",
    "    model.dropout_rate=0\n",
    "    t=1\n",
    "\n",
    "    #Training (Server side)\n",
    "    for epoch in range(nb_epochs):\n",
    "          #enables to active the \"adaptative strategy\"\n",
    "            if increasing_noise:\n",
    "                model.noise=(increasing_noise/t)\n",
    "            \n",
    "            train_loss, train_acc = train_func(train_set,model,optimizer=optimizer,scheduler=scheduler)\n",
    "            valid_loss, valid_acc = test(valid_set,model)\n",
    "            \n",
    "            if display:\n",
    "                print('Epoch: %d' %(epoch + 1))\n",
    "                print(f'\\tAcc: {train_acc * 100:.1f}%(train)')\n",
    "                print(f'\\tAcc: {valid_acc * 100:.1f}%(valid)')\n",
    "            t+=1\n",
    "\n",
    "    ## Computation of test accuracy (User side)\n",
    "\n",
    "    # We give to the model the dropout_rate and the noise level. \n",
    "    # If they were not given, they are equals to False by default\n",
    "    model.dropout_rate=dropout\n",
    "    model.noise=noise\n",
    "\n",
    "    test_loss,test_acc=test(test_set,model)\n",
    "    if display:\n",
    "        print(f'\\tAcc: {test_acc * 100:.1f}%(test)')\n",
    "      \n",
    "    return test_acc\n",
    "\n",
    "def simulation(model,train_set,valid_set,test_set,nb_epochs,epsilons=[0.05,0.1,0.5,1,5],dprates=[0.1,0.3,0.5,0.8],nb_indep_runs=3,increasing_noise=1):\n",
    "    '''This function simulates all the situations listed above for the given model and return a dataframe containing all the test accuracies\n",
    "    according to the different cases. They are computed doing an average of their values obtained after nb_indep_runs runs \n",
    "    '''\n",
    "    results=[]\n",
    "\n",
    "    all_eps=['/']\n",
    "    all_mu=['/']\n",
    "    types=['Non robust','Robust','Adaptative']\n",
    "    all_types=['Non private']\n",
    "\n",
    "    #First case\n",
    "    print('NON PRIVATE MODEL')\n",
    "    test_acc=0\n",
    "    for i in range(0,nb_indep_runs):\n",
    "        clear_output(wait=True)\n",
    "        test_acc+=train(model,train_set=train_set,valid_set=valid_set,test_set=test_set,nb_epochs=nb_epochs)\n",
    "\n",
    "    results.append(test_acc/nb_indep_runs)\n",
    "    #Second case\n",
    "    print('VARYING NOISE DROPOUT FIXED')\n",
    "    for eps in tqdm(epsilons):\n",
    "        test_acc_1,test_acc_2,test_acc_3=[0,0,0]\n",
    "        for i in range(0,nb_indep_runs):\n",
    "            test_acc_1+=train(model,train_set=train_set,valid_set=valid_set,test_set=test_set,nb_epochs=nb_epochs,dropout=False,noise=eps,noise_during_training=False)\n",
    "            test_acc_2+=train(model,train_set=train_set,valid_set=valid_set,test_set=test_set,nb_epochs=nb_epochs,dropout=False,noise=eps,noise_during_training=True)\n",
    "            test_acc_3+=train(model,train_set=train_set,valid_set=valid_set,test_set=test_set,nb_epochs=nb_epochs,dropout=False,noise=eps,increasing_noise=increasing_noise)\n",
    "      \n",
    "        for j in range(0,3):\n",
    "            all_eps.append(eps)\n",
    "            all_mu.append(0)\n",
    "            all_types.append(types[j])\n",
    "\n",
    "        results.append(test_acc_1/nb_indep_runs)\n",
    "        results.append(test_acc_2/nb_indep_runs)\n",
    "        results.append(test_acc_3/nb_indep_runs)\n",
    "        \n",
    "    #Third case\n",
    "    print('VARYING DROPOUT FIXED NOISE')\n",
    "    for mu in tqdm(dprates):\n",
    "        test_acc_1,test_acc_2,test_acc_3=[0,0,0]\n",
    "    \n",
    "        for i in range(0,nb_indep_runs):\n",
    "            test_acc_1+=train(model,train_set=train_set,valid_set=valid_set,test_set=test_set,nb_epochs=nb_epochs,dropout=mu,noise=4,noise_during_training=False)\n",
    "            test_acc_2+=train(model,train_set=train_set,valid_set=valid_set,test_set=test_set,nb_epochs=nb_epochs,dropout=mu,noise=4,noise_during_training=True)\n",
    "            test_acc_3+=train(model,train_set=train_set,valid_set=valid_set,test_set=test_set,nb_epochs=nb_epochs,dropout=mu,noise=4,increasing_noise=increasing_noise)\n",
    "    \n",
    "        for j in range(0,3):\n",
    "            all_eps.append(4)\n",
    "            all_mu.append(mu)\n",
    "            all_types.append(types[j])\n",
    "    \n",
    "        results.append(test_acc_1/nb_indep_runs)\n",
    "        results.append(test_acc_2/nb_indep_runs)\n",
    "        results.append(test_acc_3/nb_indep_runs)\n",
    "    \n",
    "    out=pd.DataFrame()\n",
    "    out['eps']=all_eps\n",
    "    out['mu']=all_mu\n",
    "    out['Type']=all_types\n",
    "    out['Test Accuracy']=np.round(results,3)\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simulation on AG-NEWS and YELP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AG_TRAIN_SIZE = len(AG_data.get_vocab())\n",
    "AG_NUM_CLASS = len(AG_data.get_labels())\n",
    "EMBED_DIM = 32\n",
    "AG_model = Classifier(vocab_size=AG_TRAIN_SIZE, embed_dim=EMBED_DIM,num_class=AG_NUM_CLASS)\n",
    "\n",
    "\n",
    "YELP_TRAIN_SIZE = len(Yelp_data.get_vocab())\n",
    "YELP_NUM_CLASS = len(Yelp_data.get_labels())\n",
    "EMBED_DIM = 32\n",
    "YELP_model = Classifier(vocab_size=YELP_TRAIN_SIZE, embed_dim=EMBED_DIM,num_class=YELP_NUM_CLASS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grab a cup of tea, the following cell takes a long time to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_AG=simulation(AG_model,AG_train_set,AG_valid_set,AG_test,nb_epochs=5,epsilons=[0.05,0.1,0.5,1,2,3,4,5],dprates=[0.1,0.3,0.5,0.8],nb_indep_runs=5)\n",
    "results_Yelp=simulation(YELP_model,Yelp_train_set,Yelp_valid_set,Yelp_test,nb_epochs=5,epsilons=[0.05,0.1,0.5,1,2,3,4,5],dprates=[0.1,0.3,0.5,0.8],nb_indep_runs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `results_AG` and `results_Yekp` Dataframe are not good for visualisation but you can see the relevant results we obtained in the following good-looking table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/Q1zyaSo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Globally, we observe that the noise has a great impact on utility as we could suspect. The robust algorithm makes its proof only when $\\epsilon=5$, i.e. with a small amount of noise and hence a small privacy guarantee.  In practice, this parameter should be optimized according to the task chosen so that the trade-off between privacy and utility is the best possible.\n",
    "\n",
    "#### Concerning our adaptative strategy, it was a complete failure here, it's equally like having a classifier which classify randomly the sentences (and that's why we didn't give its results in the table above). In fact, this is not surprising since as observed before, adding a noise level with $\\epsilon \\leq 1$ leads to bad utility for the 'robust algorithm'. We will try after if using a smaller level of noise at the beginning could help this strategy to be effective.\n",
    "\n",
    "#### Moreover, the robust strategy seems to not react well to the masking.\n",
    "\n",
    "#### How can we explain such differences with the results of the paper ?\n",
    "\n",
    "#### In the paper, they used the BERT embedding which is apparently robust against the noise by construction. Here, we have used a simple embedding which is clearly not robust to the noise as we have observed before, that could explains the gap between our results and those of the authors. In that case, we see that the strategy of the authors depend on the embedding method.\n",
    "\n",
    "#### Now, for improving our results what could we do ? Maybe increasing the size of the embedding space could be a great idea. With more information (even noisy ones), the classifier could react better. We can also change the way we update the noise in the training phase for the adaptive strategy putting for instance $\\epsilon_t = \\dfrac{10}{t}$. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AG_TRAIN_SIZE = len(AG_data.get_vocab())\n",
    "AG_NUM_CLASS = len(AG_data.get_labels())\n",
    "EMBED_DIM = 64\n",
    "AG_model = Classifier(vocab_size=AG_TRAIN_SIZE, embed_dim=EMBED_DIM,num_class=AG_NUM_CLASS)\n",
    "\n",
    "results_AG=simulation(AG_model,AG_train_set,AG_valid_set,AG_test,nb_epochs=5,epsilons=[0.05,0.1,0.5,1,2,3,4,5],dprates=[0.1,0.3,0.5,0.8],nb_indep_runs=5,increasing_noise=10)\n",
    "\n",
    "YELP_TRAIN_SIZE = len(Yelp_data.get_vocab())\n",
    "YELP_NUM_CLASS = len(Yelp_data.get_labels())\n",
    "EMBED_DIM = 64\n",
    "YELP_model = Classifier(vocab_size=YELP_TRAIN_SIZE, embed_dim=EMBED_DIM,num_class=YELP_NUM_CLASS)\n",
    "\n",
    "results_YELP=simulation(YELP_model,Yelp_train_set,Yelp_valid_set,Yelp_test,nb_epochs=5,epsilons=[0.05,0.1,0.5,1,2,3,4,5],dprates=[0.1,0.3,0.5,0.8],nb_indep_runs=5,increasing_noise=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The results found are gathered in the following table :\n",
    "![](https://i.imgur.com/0cnWpaO.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This time, the results are promising for the adaptative strategy.\n",
    "\n",
    "### What we see is really interesting and could lead to further investigation. It seems that the adaptative strategy could be helpful precisely in situations where the robust strategy isn't efficient, i.e. when the noise level is rather high. On the contrary, when the noise level is rather low, the robust strategy seems to perform better than our adaptative one. So, in some sense, these are complementaries strategies and one could think about using one or the other according to the maximum level of noise added by the user."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
